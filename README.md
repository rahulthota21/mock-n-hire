# Mockâ€™nâ€‘Hire â€” AIâ€‘Powered Hiring Suite

[![Conference](https://img.shields.io/badge/ICCCNT%202025-Accepted-blue)](https://16icccnt.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](#-license)

**Mockâ€™nâ€‘Hire** streamlines hiring endâ€‘toâ€‘end: it semantically ranks resumes against a job description and delivers realâ€‘time, emotionâ€‘aware feedback during mock interviews. Recruiters get configurable, biasâ€‘resistant rankings; candidates get targeted practice and actionable insights.

---

## ðŸ”Ž At a Glance

- **AI Resume Ranking** â€” Goes beyond keyword matching using LLMâ€‘powered semantic scoring aligned to a roleâ€™s requirements.
- **Custom Weights for Recruiters** â€” Tune the importance of Experience, Projects, Certifications, etc., per role.
- **Personalized Mock Interviews** â€” Questions are generated from each candidateâ€™s own resume (technical / HR / situational).
- **Realâ€‘Time Emotion & Stress Analysis** â€” A MobileNetV2â€‘based model analyzes video responses and surfaces objective cues.
- **Unified Dashboards** â€” Recruiters manage screenings; candidates practice and review detailed reports.
- **Measured Performance** â€” Internal evaluations report ~86.4% precision@10 for resume selection and >82% accuracy in stress identification on a heldâ€‘out set. *(Replace with your latest numbers or link to your paper/report.)*

> ðŸ“£ **Accepted at ICCCNT 2025** â€” 16th International Conference on Computing, Communication and Networking Technologies (ICCCNT 2025).

---

## ðŸ“¸ Screenshots

| Recruiter Dashboard | Candidate Screening & Analysis |
| :---: | :---: |
| ![Recruiter dashboard showing screening campaigns](Recruiter.png) | ![Detailed candidate view with score breakdown](Screening.png) |

> Ensure these images exist at the project root or update paths accordingly.

---

## ðŸ— Architecture Overview

```
[Recruiter UI (Next.js/React)]
        â”‚
        â–¼
[FastAPI Backend] â”€â”€â–º [LLM Resume Ranking + Scoring]
        â”‚                         â”‚
        â”‚                         â””â”€â–º [Custom Weights per Role]
        â”‚
        â”œâ”€â–º [/interview/questions]  (resumeâ€‘aware question generation)
        â””â”€â–º [/interview/analyze]    (MobileNetV2 emotion/stress inference)

[Supabase: Auth + PostgreSQL + Storage]
        â–²
        â”‚
[Candidate UI (Next.js/React)] â”€â”€â–º Mock interview capture & analytics
```

**Key Roles**  
- **Recruiters** upload JDs & resumes, configure weights, and review ranked shortlists.  
- **Candidates** practice with generated questions; receive realâ€‘time feedback and postâ€‘session analytics.

---

## ðŸ§° Tech Stack

| Category | Technologies |
| :--- | :--- |
| **Frontend** | Next.js, React, Tailwind CSS |
| **Backend** | Python, FastAPI |
| **AI/ML** | LLMs (e.g., Mistralâ€‘8x7B), Sentence Transformers, MobileNetV2, TensorFlow |
| **Data & Cloud** | Supabase (Auth, PostgreSQL, Storage) |

> Swap LLMs/providers as needed (e.g., OpenAI, local via Ollama).

---

## ðŸš€ Getting Started (Local)

### Prerequisites
- Python **3.9+**
- Node.js **18+** and npm
- A **Supabase** project (URL + keys)
- (Recommended) **FFmpeg** for reliable media handling

### 1) Clone
```bash
git clone https://github.com/your-username/mock-n-hire.git
cd mock-n-hire
```

### 2) Backend Setup
```bash
cd server
python -m venv venv
# Windows: venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate
pip install -r requirements.txt
```

### 3) Frontend Setup
```bash
cd ..
npm install
```

### 4) Environment Variables

Create **`./.env.local`** (frontend):
```bash
NEXT_PUBLIC_SUPABASE_URL=your_supabase_url
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_supabase_anon_key
NEXT_PUBLIC_API_BASE_URL=http://localhost:8000
```

Create **`./server/.env`** (backend):
```bash
SUPABASE_URL=your_supabase_url
SUPABASE_SERVICE_ROLE_KEY=your_supabase_service_role_key
# Choose one of the following depending on your setup
OPENAI_API_KEY=your_openai_key
MISTRAL_API_KEY=your_mistral_key
OLLAMA_BASE_URL=http://localhost:11434
# Path or identifier for emotion model (example)
EMOTION_MODEL_PATH=models/mobilenetv2_emotion.onnx
ALLOWED_ORIGINS=http://localhost:3000
```

> **Security**: Never commit `.env*` files. Use Supabase **RLS** and minimal serviceâ€‘role usage serverâ€‘side only.

### 5) Run
**Backend:**
```bash
cd server
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

**Frontend:**
```bash
cd ..
npm run dev
# open http://localhost:3000
```

---

## ðŸ”Œ Core Endpoints (Illustrative)

> Check your `server/` routes for exact names; adapt as needed.

- `POST /rank` â€” Accepts a JD + resumes; returns ranked candidates and score breakdowns.  
- `POST /interview/questions` â€” Generates resumeâ€‘aware interview questions.  
- `POST /interview/analyze` â€” Streams/accepts video/audio; returns emotion & stress metrics.  

---

## ðŸ§ª Benchmarks & Evaluation

- **Resume Ranking**: report precision@K/recall@K vs. recruiterâ€‘approved ground truth; add ablations for weight settings.  
- **Emotion/Stress**: report accuracy/F1 on heldâ€‘out data; include confusion matrix & latency metrics.  
- **Fairness/Robustness**: measure variance across demographic proxies; document mitigation steps.

> Replace this section with your latest numbers, dataset notes, and evaluation protocol or link to your paper/preprint.

---

## ðŸ” Privacy & Ethics

- Explicit consent for recording/analysis in mock interviews.  
- Secure storage via Supabase; apply Rowâ€‘Level Security (RLS).  
- Configurable retention; easy deletion on request.  
- Avoid demographic inferences; document limitations and intended use.

---

## ðŸ“ Repository Layout

```
.
â”œâ”€â”€ app/           # Next.js (pages/app directory)
â”œâ”€â”€ components/    # Reusable React components
â”œâ”€â”€ hooks/         # Custom React hooks
â”œâ”€â”€ lib/           # Utilities
â”œâ”€â”€ new_frontend/  # Alternative UI assets (optional)
â”œâ”€â”€ server/        # FastAPI backend
â”œâ”€â”€ .eslintrc.json # Lint rules
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ðŸ§­ Roadmap

- [ ] Add recruitersâ€™ collaborative workflows and notes  
- [ ] Streaming LLM responses for interviews  
- [ ] Exportable reports (PDF) for candidate feedback  
- [ ] Docker Compose for 1â€‘command local setup  
- [ ] Model cards & datasheets for ML components

---

## ðŸ¤ Contributing

1. Fork & create a feature branch.  
2. Keep PRs focused; add tests where possible.  
3. Follow the existing code style (ESLint/black/isort).

---

## ðŸ“ Citation

> **ICCCNT 2025 (Accepted).** Update this section with your final paper/preprint and BibTeX once available.

---

## ðŸ‘¥ Authors

- **Kowshik Naidu Padala**  
- **Rahul Thota**  
- **Teja Sai Sathwik Peruri**  
- **Anjali T**  

(Amrita Vishwa Vidyapeetham, India)

---

## ðŸ“œ License

This project is distributed under the **MIT License**. See [LICENSE](./LICENSE) for details.
